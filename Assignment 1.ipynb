{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Assignment 1</center></h1>\n",
    "<h2><center>Building an Information Retrieval System</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Instructions:</h4>\n",
    "* **DO NOT PLAGIARISE** (This can lead to straight F in the Course)\n",
    "\n",
    "* Follow the instructions given in the code cells that are written in comments\n",
    "\n",
    "* Remember! We will enter a query and you should print the ranked list of document names\n",
    "\n",
    "* **Deadline: Monday (October 28) 10:00AM**\n",
    "\n",
    "* Submit your Assignment as .ipynb file with your roll number as the file name. Like **\"BSEF16M501.ipynb\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improt the required Libraries\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A00-1000.pdf.txt',\n",
       " 'A00-1001.pdf.txt',\n",
       " 'A00-1002.pdf.txt',\n",
       " 'A00-1003.pdf.txt',\n",
       " 'A00-1004.pdf.txt',\n",
       " 'A00-1005.pdf.txt',\n",
       " 'A00-1006.pdf.txt',\n",
       " 'A00-1007.pdf.txt',\n",
       " 'A00-1008.pdf.txt',\n",
       " 'A00-1009.pdf.txt',\n",
       " 'A00-1010.pdf.txt',\n",
       " 'A00-1011.pdf.txt',\n",
       " 'A00-1012.pdf.txt',\n",
       " 'A00-1013.pdf.txt',\n",
       " 'A00-1014.pdf.txt',\n",
       " 'A00-1015.pdf.txt',\n",
       " 'A00-1016.pdf.txt',\n",
       " 'A00-1017.pdf.txt',\n",
       " 'A00-1018.pdf.txt',\n",
       " 'A00-1019.pdf.txt',\n",
       " 'A00-1020.pdf.txt',\n",
       " 'A00-1021.pdf.txt',\n",
       " 'A00-1022.pdf.txt',\n",
       " 'A00-1023.pdf.txt',\n",
       " 'A00-1024.pdf.txt',\n",
       " 'A00-1025.pdf.txt',\n",
       " 'A00-1026.pdf.txt',\n",
       " 'A00-1027.pdf.txt',\n",
       " 'A00-1028.pdf.txt',\n",
       " 'A00-1029.pdf.txt',\n",
       " 'A00-1030.pdf.txt',\n",
       " 'A00-1031.pdf.txt',\n",
       " 'A00-1032.pdf.txt',\n",
       " 'A00-1033.pdf.txt',\n",
       " 'A00-1034.pdf.txt',\n",
       " 'A00-1035.pdf.txt',\n",
       " 'A00-1036.pdf.txt',\n",
       " 'A00-1037.pdf.txt',\n",
       " 'A00-1038.pdf.txt',\n",
       " 'A00-1039.pdf.txt',\n",
       " 'A00-1040.pdf.txt',\n",
       " 'A00-1041.pdf.txt',\n",
       " 'A00-1042.pdf.txt',\n",
       " 'A00-1043.pdf.txt',\n",
       " 'A00-1044.pdf.txt',\n",
       " 'A00-1045.pdf.txt',\n",
       " 'A00-1046.pdf.txt',\n",
       " 'A00-2000.pdf.txt',\n",
       " 'A00-2001.pdf.txt',\n",
       " 'A00-2002.pdf.txt',\n",
       " 'A00-2003.pdf.txt',\n",
       " 'A00-2004.pdf.txt',\n",
       " 'A00-2005.pdf.txt',\n",
       " 'A00-2006.pdf.txt',\n",
       " 'A00-2007.pdf.txt',\n",
       " 'A00-2008.pdf.txt',\n",
       " 'A00-2009.pdf.txt',\n",
       " 'A00-2010.pdf.txt',\n",
       " 'A00-2011.pdf.txt',\n",
       " 'A00-2012.pdf.txt',\n",
       " 'A00-2013.pdf.txt',\n",
       " 'A00-2014.pdf.txt',\n",
       " 'A00-2015.pdf.txt',\n",
       " 'A00-2016.pdf.txt',\n",
       " 'A00-2017.pdf.txt',\n",
       " 'A00-2018.pdf.txt',\n",
       " 'A00-2019.pdf.txt',\n",
       " 'A00-2020.pdf.txt',\n",
       " 'A00-2021.pdf.txt',\n",
       " 'A00-2022.pdf.txt',\n",
       " 'A00-2023.pdf.txt',\n",
       " 'A00-2024.pdf.txt',\n",
       " 'A00-2025.pdf.txt',\n",
       " 'A00-2026.pdf.txt',\n",
       " 'A00-2027.pdf.txt',\n",
       " 'A00-2028.pdf.txt',\n",
       " 'A00-2029.pdf.txt',\n",
       " 'A00-2030.pdf.txt',\n",
       " 'A00-2031.pdf.txt',\n",
       " 'A00-2032.pdf.txt',\n",
       " 'A00-2033.pdf.txt',\n",
       " 'A00-2034.pdf.txt',\n",
       " 'A00-2035.pdf.txt',\n",
       " 'A00-2036.pdf.txt',\n",
       " 'A00-2037.pdf.txt',\n",
       " 'A00-2038.pdf.txt',\n",
       " 'A00-2039.pdf.txt',\n",
       " 'A00-2040.pdf.txt',\n",
       " 'A00-2041.pdf.txt',\n",
       " 'A00-2042.pdf.txt',\n",
       " 'A00-2043.pdf.txt',\n",
       " 'A00-3000.pdf.txt',\n",
       " 'A00-3001.pdf.txt',\n",
       " 'A00-3002.pdf.txt',\n",
       " 'A00-3003.pdf.txt',\n",
       " 'A00-3004.pdf.txt',\n",
       " 'A00-3005.pdf.txt',\n",
       " 'A00-3006.pdf.txt',\n",
       " 'A00-3007.pdf.txt',\n",
       " 'A00-3008.pdf.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the directory of our dataset of documents\n",
    "files = os.listdir('data/')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Association',\n",
       " 'for',\n",
       " '',\n",
       " 'Computational',\n",
       " 'Linguistics',\n",
       " '',\n",
       " '6',\n",
       " 'th',\n",
       " 'Applied',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '',\n",
       " 'Conference',\n",
       " '',\n",
       " 'Proceedings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Conference',\n",
       " '',\n",
       " 'April',\n",
       " '29--May',\n",
       " '4,',\n",
       " '2000',\n",
       " '',\n",
       " 'Seattle,',\n",
       " 'Washington,',\n",
       " 'USA',\n",
       " '',\n",
       " 'ANLP',\n",
       " '2000-PREFACE',\n",
       " '',\n",
       " '131',\n",
       " 'papers',\n",
       " 'were',\n",
       " 'submitted',\n",
       " 'to',\n",
       " 'ANLP-2000.',\n",
       " '46',\n",
       " 'were',\n",
       " 'accepted',\n",
       " 'for',\n",
       " 'presentation',\n",
       " 'at',\n",
       " 'the',\n",
       " 'conference.',\n",
       " '',\n",
       " 'Papers',\n",
       " 'came',\n",
       " 'from',\n",
       " '24',\n",
       " 'countries:',\n",
       " 'fifty',\n",
       " 'eight',\n",
       " 'from',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'of',\n",
       " 'America,',\n",
       " 'eleven',\n",
       " 'each',\n",
       " 'from',\n",
       " '',\n",
       " 'Germany',\n",
       " 'and',\n",
       " 'United',\n",
       " 'Kingdom,',\n",
       " 'nine',\n",
       " 'from',\n",
       " 'Canada,',\n",
       " 'eight',\n",
       " 'from',\n",
       " 'Japan,',\n",
       " 'four',\n",
       " 'each',\n",
       " 'from',\n",
       " 'Italy',\n",
       " 'and',\n",
       " '',\n",
       " 'Spain,',\n",
       " 'three',\n",
       " 'ach',\n",
       " 'from',\n",
       " 'France,',\n",
       " 'Korea',\n",
       " 'and',\n",
       " 'Switzerland,',\n",
       " 'two',\n",
       " 'each',\n",
       " 'from',\n",
       " 'Australia,',\n",
       " 'China,',\n",
       " 'The',\n",
       " '',\n",
       " 'Netherlands',\n",
       " 'and',\n",
       " 'Sweden',\n",
       " 'and',\n",
       " 'one']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following code takes all files, replaces new line character with space character and put words of all files in the Words list \n",
    "Words = []\n",
    "for f in files:\n",
    "    fhand = open(\"data/\"+f)\n",
    "    file = fhand.read()\n",
    "    file = file.replace(\"\\n\",\" \")\n",
    "    for word in file.split(\" \"):\n",
    "        Words.append(word)\n",
    "\n",
    "Words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-2b58f41733fc>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-2b58f41733fc>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#find count of unique words in all these files and store it in a dictionary\n",
    "Word_To_Count = {}\n",
    "for w in Words:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the count of Sweden\n",
    "Word_To_Count[\"Sweden\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert all text into lower case then find count of unique words,\n",
    "Small_Words = []\n",
    "#read each file, split all words and append the lower case word in Small_Words list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Small_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find count of unique words after converting them to lowercase in all these files and store it in a dictionary\n",
    "Small_Word_To_Count = {}\n",
    "for w in Small_Words:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Small_Word_To_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort the small words (in Small_Word_To_Count dictionary) by frequencies and store the results in freq.txt file\n",
    "#Each line of the file should have word seperated by comma with its counts\n",
    "#Hint: Can you use tuples to sort key value pairs in a list?\n",
    "fhand = open(\"freq.txt\",mode='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort the words by alphabatical order and store results in words.txt file\n",
    "#Each line of the file should have word seperated by comma with its counts\n",
    "fhand = open(\"words.txt\",mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list of Small_Words alphabatically and store it in a new list called Vocabulary\n",
    "# Hint: Explore Set Function\n",
    "\n",
    "Vocabulary = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the list is sorted alphabatically, \n",
    "# We can create dictionaries\n",
    "Word_to_ID = {}\n",
    "# Go through the overview.ipynb notebook and convert list items into tuples of indexes and value\n",
    "# putt all these tuples into Word_to_ID dictionary, Now we can search every words ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now inverse the key value pairs of Word_to_ID Dictionary, so that we can search each word by its ID\n",
    "ID_to_Word = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sparse matrix is a matrix that is comprised of mostly zero values.\n",
    "Sparse matrices are distinct from matrices with mostly non-zero values, which are referred to as dense matrices.\n",
    "\n",
    "\"A matrix is sparse if many of its coefficients are zero. The interest in sparsity arises because its exploitation can lead to enormous computational savings and because many large matrix problems that occur in practice are sparse.\"\n",
    "\n",
    "â€” Page 1, Direct Methods for Sparse Matrices, Second Edition, 2017.\n",
    "\n",
    "Follwing is the example of a Sparse Matrix\n",
    "\n",
    "<img src=\"Images/sparse_matrix.png\" width=\"800\" height=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space Complexity\n",
    "Very large matrices require a lot of memory, and some very large matrices that we wish to work with are sparse.\n",
    "An example of a very large matrix that is too large to be stored in memory is a link matrix that shows the links from one website to another.\n",
    "\n",
    "In this case, the matrix contained is sparse with many more zero values than data values. The problem with representing these sparse matrices as dense matrices is that memory is required and must be allocated for each 32-bit or even 64-bit zero value in the matrix.\n",
    "\n",
    "This is clearly a waste of memory resources as those zero values do not contain any information.\n",
    "\n",
    "### Time Complexity\n",
    "Assuming a very large sparse matrix can be fit into memory, we will want to perform operations on this matrix.\n",
    "\n",
    "Simply, if the matrix contains mostly zero-values, i.e. no data, then performing operations across this matrix may take a long time where the bulk of the computation performed will involve adding or multiplying zero values together.\n",
    "\n",
    "##### Learn More About Sparse Matrrices on Internet. You have to work on sparse matrices in the following tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create the following Term Document Matrix (Sparse Matrix)\n",
    "<img src=\"Images/Document_Term.JPG\" width=\"800\" height=\"400\">\n",
    "\n",
    "The Matrix has shape **No of Documents X Vocabulary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read each document and save it in a Term Document matrix\n",
    "#### The Size of document vector should be equal to the size of vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the following Term Document Matrix Having Frequency of each word (Sparse Matrix)\n",
    "<img src=\"Images/Term_Document_Frequency.JPG\" width=\"800\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't Forget the following things before proceeding further\n",
    "\n",
    "\n",
    "* **You have to perform processing on Sparse Matrices**\n",
    "* **For further tasks you have to use the Term Documents matrix that has count of words**\n",
    "* **Try to avoid for loops**\n",
    "* **Don't plagiarise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the search Query: Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "#Take Query from the User\n",
    "Query = input(\"Enter the search Query: \")\n",
    "\n",
    "#Convert the query into the query vector, This will be same as we converted each document into document vector\n",
    "#Query vector should have frequency of words\n",
    "#Take the dot product of query vector with each document vector and rank them, Avoid for loops\n",
    "#Print the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
